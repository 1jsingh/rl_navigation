{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ../python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self,state_size,action_size):\n",
    "        # initialising the super class properties\n",
    "        super(Qnetwork,self).__init__()\n",
    "        \n",
    "        # defining layers\n",
    "        self.fc1 = nn.Linear(state_size,32)\n",
    "        self.fc2 = nn.Linear(32,64)\n",
    "        self.fc3 = nn.Linear(64,128)\n",
    "        self.out = nn.Linear(128,action_size)\n",
    "        \n",
    "    def forward(self,states):\n",
    "        x = F.relu(self.fc1(states))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        out = F.relu(self.out(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from collections import deque,namedtuple\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self,buffer_size,batch_size):\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def add(self,state,action,reward,next_state,done):\n",
    "        e = self.experience(state,action,reward,next_state,done)\n",
    "        self.buffer.append(e)\n",
    "    \n",
    "    def sample(self,random=True):\n",
    "        if random:\n",
    "            choose = np.random.choice(range(len(self.buffer)),self.batch_size,replace=False)\n",
    "            experiences = [self.buffer[i] for i in choose]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states,actions,rewards,next_states,dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_EVERY = 4\n",
    "class Agent:\n",
    "    def __init__(self,state_size,action_size,gamma=0.99,lr=5e-4,\n",
    "                     buffer_size=int(1e5),batch_size=64,tau=1e-3):\n",
    "        # defining local and target networks\n",
    "        self.qnet_local = Qnetwork(state_size,action_size).to(device)\n",
    "        self.qnet_target = Qnetwork(state_size,action_size).to(device)\n",
    "        \n",
    "        # set local and target parameters equal to each other\n",
    "        #self.soft_update(tau=1.0)\n",
    "        \n",
    "        # experience replay buffer\n",
    "        self.memory = ReplayBuffer(buffer_size,batch_size)\n",
    "        \n",
    "        # defining variables\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        \n",
    "        self.t_step = 0\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam(self.qnet_local.parameters(),lr=self.lr)\n",
    "    \n",
    "    def step(self,state,action,reward,next_state,done):\n",
    "        \"\"\" saves the step info in the memory buffer and perform a learning iteration\n",
    "        Input : \n",
    "            state,action,reward,state,done : non-batched numpy arrays\n",
    "        \n",
    "        Output : \n",
    "            none\n",
    "        \"\"\"\n",
    "        # add sample to the memory buffer\n",
    "        self.memory.add(state,action,reward,next_state,done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        \n",
    "        # use replay buffer to learn if it has enough samples\n",
    "        if self.t_step == 0:\n",
    "            if len(self.memory) > self.batch_size:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences)\n",
    "        \n",
    "    def learn(self,experiences):\n",
    "        \"\"\" perform a learning iteration by using sampled experience batch\n",
    "        Input : \n",
    "            experience : tuple from the memory buffer\n",
    "            states, actions, rewards, next_states, dones = experiences\n",
    "            eg : states.shape = [N,state_size]\n",
    "        Output : \n",
    "            none\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        # set optimizer grdient to zero\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # predicted action value\n",
    "        q_pred = self.qnet_local.forward(states).gather(1,actions)\n",
    "        \n",
    "        # target action value\n",
    "        q_target = rewards + self.gamma*(1-dones)*self.qnet_target.forward(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        \n",
    "        # defining loss\n",
    "        loss = F.mse_loss(q_pred,q_target)\n",
    "        \n",
    "        # running backprop and optimizer step\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # run soft update\n",
    "        self.soft_update(self.tau)\n",
    "        \n",
    "    def act(self,state,eps=0.):\n",
    "        \"\"\" return the local model's predicted action for the given state\n",
    "        Input : \n",
    "            state : [state_size]\n",
    "        \n",
    "        Output : \n",
    "            action : scalar action as action space is discrete with dim = 1\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().to(device) # converts numpy array to torch tensor\n",
    "        \n",
    "        self.qnet_local.eval() # put net in test mode\n",
    "        with torch.no_grad():\n",
    "            max_action = np.argmax(self.qnet_local(state).cpu().data.numpy())\n",
    "        self.qnet_local.train() # put net back in train mode\n",
    "        \n",
    "        rand_num = np.random.rand() # sample a random number uniformly between 0 and 1\n",
    "        \n",
    "        # implementing epsilon greedy policy\n",
    "        if rand_num < eps:\n",
    "            return np.random.randint(self.action_size)\n",
    "        else: \n",
    "            return max_action\n",
    "        \n",
    "    def soft_update(self,tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(self.qnet_target.parameters(), self.qnet_local.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=brain.vector_observation_space_size, action_size=brain.vector_action_space_size)\n",
    "\n",
    "def dqn_train(max_episodes=1000,max_t=1000,eps_start=1.0,eps_end=1e-2,eps_decay=.995):\n",
    "        eps = eps_start\n",
    "        scores = []\n",
    "        score_window = deque(maxlen=100)\n",
    "        avg_scores = []\n",
    "        \n",
    "        for episode_count in range(max_episodes):\n",
    "            \n",
    "            # reset env state\n",
    "            env_info = env.reset(train_mode=True)[brain_name]\n",
    "            state = env_info.vector_observations[0]\n",
    "            \n",
    "            done = env_info.local_done[0]\n",
    "            total_reward = 0\n",
    "            for t in range(max_t):\n",
    "                # choose action using the local q-network\n",
    "                action = agent.act(state,eps)\n",
    "\n",
    "                # taking action in the env\n",
    "                env_info = env.step(vector_action=action)[brain_name]\n",
    "\n",
    "                # getting next_state,reward,done from the env\n",
    "                next_state = env_info.vector_observations[0]\n",
    "                reward = env_info.rewards[0]\n",
    "                done = env_info.local_done[0]\n",
    "                \n",
    "                # using agent to perform a learning step and save the sample in the memory\n",
    "                agent.step(state,action,reward,next_state,done)\n",
    "                \n",
    "                # decay the epsilon value\n",
    "                eps = max(eps_decay*eps,eps_end)\n",
    "                \n",
    "                # get total reward for the episode\n",
    "                total_reward += reward\n",
    "                \n",
    "                # set current state = next_state\n",
    "                state = next_state\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "            scores.append(total_reward)\n",
    "            score_window.append(total_reward)\n",
    "            avg_scores.append(np.mean(score_window))\n",
    "\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode_count, np.mean(score_window)), end=\"\")\n",
    "            if episode_count % 100 == 0:\n",
    "                print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(episode_count, np.mean(score_window)))\n",
    "            \n",
    "            if np.mean(score_window) > 13:\n",
    "                print('\\rLearning completed in {} episodes ... avg_score :{}'.format(episode_count, np.mean(score_window)))\n",
    "                break\n",
    "                \n",
    "        return scores,avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Score: -1.00\n",
      "Episode 100\tAverage Score: 2.44\n",
      "Episode 200\tAverage Score: 7.65\n",
      "Episode 300\tAverage Score: 12.62\n",
      "Learning completed in 330 episodes ... avg_score :13.07\n",
      "Learning completed in 331 episodes ... avg_score :13.12\n",
      "Learning completed in 332 episodes ... avg_score :13.07\n",
      "Learning completed in 333 episodes ... avg_score :13.13\n",
      "Learning completed in 334 episodes ... avg_score :13.16\n",
      "Learning completed in 335 episodes ... avg_score :13.22\n",
      "Learning completed in 336 episodes ... avg_score :13.19\n",
      "Learning completed in 337 episodes ... avg_score :13.22\n",
      "Learning completed in 338 episodes ... avg_score :13.28\n",
      "Learning completed in 339 episodes ... avg_score :13.28\n",
      "Learning completed in 340 episodes ... avg_score :13.26\n",
      "Learning completed in 341 episodes ... avg_score :13.18\n",
      "Learning completed in 342 episodes ... avg_score :13.2\n",
      "Learning completed in 343 episodes ... avg_score :13.2\n",
      "Learning completed in 344 episodes ... avg_score :13.21\n",
      "Learning completed in 345 episodes ... avg_score :13.15\n",
      "Learning completed in 346 episodes ... avg_score :13.17\n",
      "Learning completed in 347 episodes ... avg_score :13.19\n",
      "Learning completed in 348 episodes ... avg_score :13.26\n",
      "Learning completed in 349 episodes ... avg_score :13.3\n",
      "Learning completed in 350 episodes ... avg_score :13.35\n",
      "Learning completed in 351 episodes ... avg_score :13.41\n",
      "Learning completed in 352 episodes ... avg_score :13.4\n",
      "Learning completed in 353 episodes ... avg_score :13.37\n",
      "Learning completed in 354 episodes ... avg_score :13.33\n",
      "Learning completed in 355 episodes ... avg_score :13.36\n",
      "Learning completed in 356 episodes ... avg_score :13.33\n",
      "Learning completed in 357 episodes ... avg_score :13.37\n",
      "Learning completed in 358 episodes ... avg_score :13.4\n",
      "Learning completed in 359 episodes ... avg_score :13.38\n",
      "Learning completed in 360 episodes ... avg_score :13.45\n",
      "Learning completed in 361 episodes ... avg_score :13.49\n",
      "Learning completed in 362 episodes ... avg_score :13.49\n",
      "Learning completed in 363 episodes ... avg_score :13.49\n",
      "Learning completed in 364 episodes ... avg_score :13.51\n",
      "Learning completed in 365 episodes ... avg_score :13.56\n",
      "Learning completed in 366 episodes ... avg_score :13.64\n",
      "Learning completed in 367 episodes ... avg_score :13.61\n",
      "Learning completed in 368 episodes ... avg_score :13.65\n",
      "Learning completed in 369 episodes ... avg_score :13.63\n",
      "Learning completed in 370 episodes ... avg_score :13.57\n",
      "Learning completed in 371 episodes ... avg_score :13.75\n",
      "Learning completed in 372 episodes ... avg_score :13.75\n",
      "Learning completed in 373 episodes ... avg_score :13.8\n",
      "Learning completed in 374 episodes ... avg_score :13.83\n",
      "Learning completed in 375 episodes ... avg_score :13.82\n",
      "Learning completed in 376 episodes ... avg_score :13.75\n",
      "Learning completed in 377 episodes ... avg_score :13.81\n",
      "Learning completed in 378 episodes ... avg_score :13.73\n",
      "Learning completed in 379 episodes ... avg_score :13.67\n",
      "Learning completed in 380 episodes ... avg_score :13.78\n",
      "Learning completed in 381 episodes ... avg_score :13.79\n",
      "Learning completed in 382 episodes ... avg_score :13.84\n",
      "Learning completed in 383 episodes ... avg_score :13.84\n",
      "Learning completed in 384 episodes ... avg_score :13.83\n",
      "Learning completed in 385 episodes ... avg_score :13.92\n",
      "Learning completed in 386 episodes ... avg_score :13.84\n",
      "Learning completed in 387 episodes ... avg_score :13.84\n",
      "Learning completed in 388 episodes ... avg_score :13.83\n",
      "Learning completed in 389 episodes ... avg_score :13.8\n",
      "Learning completed in 390 episodes ... avg_score :13.86\n",
      "Learning completed in 391 episodes ... avg_score :13.89\n",
      "Learning completed in 392 episodes ... avg_score :13.97\n",
      "Learning completed in 393 episodes ... avg_score :14.01\n",
      "Learning completed in 394 episodes ... avg_score :14.02\n",
      "Learning completed in 395 episodes ... avg_score :14.11\n",
      "Learning completed in 396 episodes ... avg_score :14.1\n",
      "Learning completed in 397 episodes ... avg_score :14.13\n",
      "Learning completed in 398 episodes ... avg_score :14.06\n",
      "Learning completed in 399 episodes ... avg_score :14.11\n",
      "Episode 400\tAverage Score: 14.12\n",
      "Learning completed in 400 episodes ... avg_score :14.12\n",
      "Learning completed in 401 episodes ... avg_score :14.14\n",
      "Learning completed in 402 episodes ... avg_score :14.15\n",
      "Learning completed in 403 episodes ... avg_score :14.17\n",
      "Learning completed in 404 episodes ... avg_score :14.17\n",
      "Learning completed in 405 episodes ... avg_score :14.15\n",
      "Learning completed in 406 episodes ... avg_score :14.09\n",
      "Learning completed in 407 episodes ... avg_score :14.11\n",
      "Learning completed in 408 episodes ... avg_score :14.12\n",
      "Learning completed in 409 episodes ... avg_score :14.09\n",
      "Learning completed in 410 episodes ... avg_score :14.12\n",
      "Learning completed in 411 episodes ... avg_score :14.07\n",
      "Learning completed in 412 episodes ... avg_score :14.25\n",
      "Learning completed in 413 episodes ... avg_score :14.21\n",
      "Learning completed in 414 episodes ... avg_score :14.31\n",
      "Learning completed in 415 episodes ... avg_score :14.29\n",
      "Learning completed in 416 episodes ... avg_score :14.26\n",
      "Learning completed in 417 episodes ... avg_score :14.3\n",
      "Learning completed in 418 episodes ... avg_score :14.37\n",
      "Learning completed in 419 episodes ... avg_score :14.31\n",
      "Learning completed in 420 episodes ... avg_score :14.3\n",
      "Learning completed in 421 episodes ... avg_score :14.3\n",
      "Learning completed in 422 episodes ... avg_score :14.23\n",
      "Learning completed in 423 episodes ... avg_score :14.26\n",
      "Learning completed in 424 episodes ... avg_score :14.13\n",
      "Learning completed in 425 episodes ... avg_score :14.2\n",
      "Learning completed in 426 episodes ... avg_score :14.27\n",
      "Learning completed in 427 episodes ... avg_score :14.23\n",
      "Learning completed in 428 episodes ... avg_score :14.17\n",
      "Learning completed in 429 episodes ... avg_score :14.18\n",
      "Learning completed in 430 episodes ... avg_score :14.19\n",
      "Learning completed in 431 episodes ... avg_score :14.19\n",
      "Learning completed in 432 episodes ... avg_score :14.28\n",
      "Learning completed in 433 episodes ... avg_score :14.27\n",
      "Learning completed in 434 episodes ... avg_score :14.26\n",
      "Learning completed in 435 episodes ... avg_score :14.33\n",
      "Learning completed in 436 episodes ... avg_score :14.35\n",
      "Learning completed in 437 episodes ... avg_score :14.43\n",
      "Learning completed in 438 episodes ... avg_score :14.44\n",
      "Learning completed in 439 episodes ... avg_score :14.46\n",
      "Learning completed in 440 episodes ... avg_score :14.55\n",
      "Learning completed in 441 episodes ... avg_score :14.57\n",
      "Learning completed in 442 episodes ... avg_score :14.56\n",
      "Learning completed in 443 episodes ... avg_score :14.58\n",
      "Learning completed in 444 episodes ... avg_score :14.69\n",
      "Learning completed in 445 episodes ... avg_score :14.79\n",
      "Learning completed in 446 episodes ... avg_score :14.74\n",
      "Learning completed in 447 episodes ... avg_score :14.78\n",
      "Learning completed in 448 episodes ... avg_score :14.79\n",
      "Learning completed in 449 episodes ... avg_score :14.72\n",
      "Learning completed in 450 episodes ... avg_score :14.73\n",
      "Learning completed in 451 episodes ... avg_score :14.76\n",
      "Learning completed in 452 episodes ... avg_score :14.74\n",
      "Learning completed in 453 episodes ... avg_score :14.78\n",
      "Learning completed in 454 episodes ... avg_score :14.75\n",
      "Learning completed in 455 episodes ... avg_score :14.7\n",
      "Learning completed in 456 episodes ... avg_score :14.73\n",
      "Learning completed in 457 episodes ... avg_score :14.8\n",
      "Learning completed in 458 episodes ... avg_score :14.78\n",
      "Learning completed in 459 episodes ... avg_score :14.83\n",
      "Learning completed in 460 episodes ... avg_score :14.86\n",
      "Learning completed in 461 episodes ... avg_score :14.91\n",
      "Learning completed in 462 episodes ... avg_score :14.98\n",
      "Learning completed in 463 episodes ... avg_score :15.04\n",
      "Learning completed in 464 episodes ... avg_score :14.99\n",
      "Learning completed in 465 episodes ... avg_score :15.03\n",
      "Learning completed in 466 episodes ... avg_score :14.98\n",
      "Learning completed in 467 episodes ... avg_score :14.94\n",
      "Learning completed in 468 episodes ... avg_score :14.98\n",
      "Learning completed in 469 episodes ... avg_score :15.05\n",
      "Learning completed in 470 episodes ... avg_score :15.13\n",
      "Learning completed in 471 episodes ... avg_score :15.05\n",
      "Learning completed in 472 episodes ... avg_score :15.12\n",
      "Learning completed in 473 episodes ... avg_score :15.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning completed in 474 episodes ... avg_score :15.17\n",
      "Learning completed in 475 episodes ... avg_score :15.21\n",
      "Learning completed in 476 episodes ... avg_score :15.31\n",
      "Learning completed in 477 episodes ... avg_score :15.34\n",
      "Learning completed in 478 episodes ... avg_score :15.35\n",
      "Learning completed in 479 episodes ... avg_score :15.41\n",
      "Learning completed in 480 episodes ... avg_score :15.38\n",
      "Learning completed in 481 episodes ... avg_score :15.34\n",
      "Learning completed in 482 episodes ... avg_score :15.38\n",
      "Learning completed in 483 episodes ... avg_score :15.37\n",
      "Learning completed in 484 episodes ... avg_score :15.4\n",
      "Learning completed in 485 episodes ... avg_score :15.41\n",
      "Learning completed in 486 episodes ... avg_score :15.47\n",
      "Learning completed in 487 episodes ... avg_score :15.41\n",
      "Learning completed in 488 episodes ... avg_score :15.41\n",
      "Learning completed in 489 episodes ... avg_score :15.46\n",
      "Learning completed in 490 episodes ... avg_score :15.46\n",
      "Learning completed in 491 episodes ... avg_score :15.48\n",
      "Learning completed in 492 episodes ... avg_score :15.42\n",
      "Learning completed in 493 episodes ... avg_score :15.47\n",
      "Learning completed in 494 episodes ... avg_score :15.48\n",
      "Learning completed in 495 episodes ... avg_score :15.56\n",
      "Learning completed in 496 episodes ... avg_score :15.61\n",
      "Learning completed in 497 episodes ... avg_score :15.55\n",
      "Learning completed in 498 episodes ... avg_score :15.58\n",
      "Learning completed in 499 episodes ... avg_score :15.58\n"
     ]
    }
   ],
   "source": [
    "scores,avg_scores = dqn_train(max_episodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a302e8208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(avg_scores)),avg_scores)\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('avg score for last 100 episodes')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
